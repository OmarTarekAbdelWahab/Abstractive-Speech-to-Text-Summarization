{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10112502,"sourceType":"datasetVersion","datasetId":6238905,"isSourceIdPinned":true},{"sourceId":10141776,"sourceType":"datasetVersion","datasetId":6259697},{"sourceId":10141937,"sourceType":"datasetVersion","datasetId":6259829},{"sourceId":10209081,"sourceType":"datasetVersion","datasetId":6309587},{"sourceId":10209117,"sourceType":"datasetVersion","datasetId":6309610}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:35:00.654632Z","iopub.execute_input":"2025-04-24T17:35:00.654871Z","iopub.status.idle":"2025-04-24T17:35:00.883285Z","shell.execute_reply.started":"2025-04-24T17:35:00.654854Z","shell.execute_reply":"2025-04-24T17:35:00.882600Z"}},"outputs":[{"name":"stdout","text":"Thu Apr 24 17:35:00 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   34C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nASR_CHECKPOINT_LINK = user_secrets.get_secret(\"ASR_CHECKPOINT_FOLDER\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:35:00.884908Z","iopub.execute_input":"2025-04-24T17:35:00.885141Z","iopub.status.idle":"2025-04-24T17:35:01.034858Z","shell.execute_reply.started":"2025-04-24T17:35:00.885122Z","shell.execute_reply":"2025-04-24T17:35:01.034338Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!rm -rf /kaggle/working/llm-speech-summarization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:35:01.035418Z","iopub.execute_input":"2025-04-24T17:35:01.035630Z","iopub.status.idle":"2025-04-24T17:35:01.153071Z","shell.execute_reply.started":"2025-04-24T17:35:01.035614Z","shell.execute_reply":"2025-04-24T17:35:01.152316Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!git clone https://github.com/karimfathy054/llm-speech-summarization.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:35:01.155085Z","iopub.execute_input":"2025-04-24T17:35:01.155284Z","iopub.status.idle":"2025-04-24T17:35:01.970282Z","shell.execute_reply.started":"2025-04-24T17:35:01.155265Z","shell.execute_reply":"2025-04-24T17:35:01.969033Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'llm-speech-summarization'...\nremote: Enumerating objects: 387, done.\u001b[K\nremote: Counting objects: 100% (93/93), done.\u001b[K\nremote: Compressing objects: 100% (64/64), done.\u001b[K\nremote: Total 387 (delta 62), reused 45 (delta 29), pack-reused 294 (from 1)\u001b[K\nReceiving objects: 100% (387/387), 164.14 KiB | 2.98 MiB/s, done.\nResolving deltas: 100% (189/189), done.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -r /kaggle/working/llm-speech-summarization/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:35:01.971544Z","iopub.execute_input":"2025-04-24T17:35:01.971857Z","iopub.status.idle":"2025-04-24T17:37:52.805691Z","shell.execute_reply.started":"2025-04-24T17:35:01.971825Z","shell.execute_reply":"2025-04-24T17:37:52.804914Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting accelerate==0.26.1 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 1))\n  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: audioread==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 2)) (3.0.1)\nCollecting datasets==2.16.1 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 3))\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nCollecting huggingface-hub==0.20.3 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 4))\n  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\nCollecting librosa==0.9.2 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 5))\n  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 6)) (2.3.0)\nCollecting safetensors==0.4.2 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 7))\n  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 8)) (1.15.2)\nCollecting sentencepiece==0.1.97 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 9))\n  Downloading sentencepiece-0.1.97.tar.gz (524 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.7/524.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting soundfile==0.12.1 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 10))\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\nCollecting tensorboard==2.16.2 (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 11))\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 12)) (0.21.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (2.5.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 14)) (2.5.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 15)) (4.51.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (3.18.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (19.0.1)\nCollecting pyarrow-hotfix (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3))\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3))\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3))\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (3.11.16)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.3->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 4)) (4.13.1)\nRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (1.4.2)\nRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (4.4.2)\nCollecting resampy>=0.2.2 (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5))\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (0.60.0)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (1.8.2)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 6)) (4.9.3)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile==0.12.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 10)) (1.17.1)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (1.70.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (3.1.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 13)) (1.3.0)\nINFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 15))\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\nINFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.43.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.43.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.42.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.42.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 15)) (2024.11.6)\nCollecting tokenizers (from -r /kaggle/working/llm-speech-summarization/requirements.txt (line 12))\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile==0.12.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 10)) (2.22)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (1.19.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.45.1->librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (4.3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2025.1.31)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 5)) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard==2.16.2->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 11)) (3.0.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3))\n  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 3)) (2025.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->accelerate==0.26.1->-r /kaggle/working/llm-speech-summarization/requirements.txt (line 1)) (2024.2.0)\nDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading librosa-0.9.2-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nBuilding wheels for collected packages: sentencepiece\n  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sentencepiece: filename=sentencepiece-0.1.97-cp311-cp311-linux_x86_64.whl size=1244399 sha256=010838970f6a2218bbe164d80a4d05654257f9face41dc9c8ef9275819162b06\n  Stored in directory: /root/.cache/pip/wheels/04/dd/ab/6e3d4b6b17fe7ca0f54548ae20941c40bb3f15839d66f5598c\nSuccessfully built sentencepiece\nInstalling collected packages: sentencepiece, safetensors, pyarrow-hotfix, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, dill, soundfile, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, tokenizers, nvidia-cusolver-cu12, resampy, transformers, tensorboard, librosa, datasets, accelerate\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.2.0\n    Uninstalling sentencepiece-0.2.0:\n      Successfully uninstalled sentencepiece-0.2.0\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.5.2\n    Uninstalling safetensors-0.5.2:\n      Successfully uninstalled safetensors-0.5.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: soundfile\n    Found existing installation: soundfile 0.13.1\n    Uninstalling soundfile-0.13.1:\n      Successfully uninstalled soundfile-0.13.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.30.2\n    Uninstalling huggingface-hub-0.30.2:\n      Successfully uninstalled huggingface-hub-0.30.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.10.2.post1\n    Uninstalling librosa-0.10.2.post1:\n      Successfully uninstalled librosa-0.10.2.post1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.5.0\n    Uninstalling datasets-3.5.0:\n      Successfully uninstalled datasets-3.5.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.3.0\n    Uninstalling accelerate-1.3.0:\n      Successfully uninstalled accelerate-1.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ndiffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.20.3 which is incompatible.\nsentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npeft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.20.3 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.16.2 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 fsspec-2023.10.0 huggingface-hub-0.20.3 librosa-0.9.2 multiprocess-0.70.15 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-hotfix-0.6 resampy-0.4.3 safetensors-0.4.2 sentencepiece-0.1.97 soundfile-0.12.1 tensorboard-2.16.2 tokenizers-0.19.1 transformers-4.40.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import gdown\ngdown.download_folder(ASR_CHECKPOINT_LINK)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:37:52.806703Z","iopub.execute_input":"2025-04-24T17:37:52.807327Z","iopub.status.idle":"2025-04-24T17:38:04.504204Z","shell.execute_reply.started":"2025-04-24T17:37:52.807300Z","shell.execute_reply":"2025-04-24T17:38:04.503476Z"}},"outputs":[{"name":"stderr","text":"Retrieving folder contents\n","output_type":"stream"},{"name":"stdout","text":"Processing file 1wE7aghYl3Wy-BIn-QgY95z69LiDsUt6O speech_llm_audio_encoder.pt\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1wE7aghYl3Wy-BIn-QgY95z69LiDsUt6O\nFrom (redirected): https://drive.google.com/uc?id=1wE7aghYl3Wy-BIn-QgY95z69LiDsUt6O&confirm=t&uuid=0eff915f-b038-4796-bfc7-562af0dd3a24\nTo: /kaggle/working/Audio encoder checkpoint/speech_llm_audio_encoder.pt\n100%|██████████| 1.27G/1.27G [00:07<00:00, 173MB/s] \nDownload completed\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/Audio encoder checkpoint/speech_llm_audio_encoder.pt']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# sanity check\n# change the folder name if changed\n\n!python /kaggle/working/llm-speech-summarization/inference.py -c /kaggle/working/llm-speech-summarization/config/config_full.yaml -g 0 -p \"/kaggle/working/Audio encoder checkpoint/speech_llm_audio_encoder.pt\" -a \"/kaggle/input/audio-summarization-filtered-testset/audios/000571afe702684d90c1d222ce70b1e1375c1016.wav\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:38:04.505144Z","iopub.execute_input":"2025-04-24T17:38:04.505599Z","iopub.status.idle":"2025-04-24T17:38:27.760575Z","shell.execute_reply.started":"2025-04-24T17:38:04.505552Z","shell.execute_reply":"2025-04-24T17:38:27.759864Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/llm-speech-summarization/inference.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(audio_encoder_checkpoint, map_location=\"cpu\")\nconfig.json: 100%|█████████████████████████| 1.38k/1.38k [00:00<00:00, 8.50MB/s]\npytorch_model.bin: 100%|████████████████████| 1.26G/1.26G [00:05<00:00, 243MB/s]\nSome weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTraceback (most recent call last):\n  File \"/kaggle/working/llm-speech-summarization/inference.py\", line 326, in <module>\n    llm_inferencer = LLMSpeechTextInference(\n                     ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/llm-speech-summarization/inference.py\", line 23, in __init__\n    self.audio_encoder.eval().to(self.devices[0])\n                                 ~~~~~~~~~~~~^^^\nTypeError: 'torch.device' object is not subscriptable\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%cd /kaggle/working/llm-speech-summarization\nfrom inference import load_model , user_inference, LLMSpeechTextInference\nllm_model = load_model(\"/kaggle/working/llm-speech-summarization/config/config_full.yaml\",0,\n               \"/kaggle/working/Audio encoder checkpoint/speech_llm_audio_encoder.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:38:27.761766Z","iopub.execute_input":"2025-04-24T17:38:27.762078Z","iopub.status.idle":"2025-04-24T17:39:12.514189Z","shell.execute_reply.started":"2025-04-24T17:38:27.762044Z","shell.execute_reply":"2025-04-24T17:39:12.513361Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/llm-speech-summarization\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/llm-speech-summarization/inference.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(audio_encoder_checkpoint, map_location=\"cpu\")\nSome weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loaded audio encoder.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"743dde1db46548ab80404b8a6ca69879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/749k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"377606a8bf8249bd8d1ddbe1449773c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e9d4370bcb4f9a8f7949ce647c4edd"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca1e621abfa4325bd6f200c55b2f73b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.04G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"190cfddb14d946cb80c4cd545d0b0cdc"}},"metadata":{}},{"name":"stdout","text":"Loaded LLM.\n\ndone\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"sample_audio = \"/kaggle/input/audio-summarization-filtered-testset/audios/000571afe702684d90c1d222ce70b1e1375c1016.wav\"\ntext_prompt = \"summarize in bullet points\"\nresponse1 = user_inference(llm_model,sample_audio,user_prompt=\"text_prompt\")\n# torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:12.515094Z","iopub.execute_input":"2025-04-24T17:39:12.515533Z","iopub.status.idle":"2025-04-24T17:39:33.739658Z","shell.execute_reply.started":"2025-04-24T17:39:12.515511Z","shell.execute_reply":"2025-04-24T17:39:33.739055Z"}},"outputs":[{"name":"stdout","text":"combined_embeds:\ntensor([[[ 1.2634e-02,  2.6855e-02, -1.0559e-02,  ...,  4.5166e-03,\n           1.3245e-02, -2.0386e-02],\n         [ 1.0254e-02,  1.3477e-01, -2.0020e-02,  ...,  1.0559e-02,\n           3.4180e-02,  2.5024e-02],\n         [-8.6060e-03,  1.4587e-02, -9.8267e-03,  ..., -3.7354e-02,\n           1.2894e-03,  3.8086e-02],\n         ...,\n         [ 2.1242e+00, -2.4979e-01,  1.2839e+00,  ...,  1.0408e+00,\n          -2.0490e-01,  3.5563e-02],\n         [ 1.8539e+00, -9.8526e-03,  1.0844e+00,  ...,  1.4585e+00,\n          -1.7900e-01,  4.5060e-01],\n         [ 8.8512e-01,  2.0134e-01,  4.5713e-01,  ...,  7.0709e-01,\n          -1.6380e-01,  3.1541e-01]]], device='cuda:1')\ncombined_embeds shape:\ntorch.Size([1, 1092, 3072])\nprompt_emb_sequence:\ntensor([[[ 0.0547, -0.0388, -0.0757,  ..., -0.0005,  0.0023,  0.0005],\n         [ 0.0219, -0.0352,  0.0055,  ..., -0.0233, -0.0206,  0.0064],\n         [-0.0078, -0.0425, -0.0043,  ...,  0.0247,  0.0167,  0.0415],\n         ...,\n         [-0.0205,  0.0031,  0.0062,  ...,  0.0101,  0.0057, -0.0048],\n         [-0.0078, -0.0425, -0.0043,  ...,  0.0247,  0.0167,  0.0415],\n         [ 0.0182, -0.0532, -0.0156,  ...,  0.0057,  0.0012, -0.0063]]],\n       device='cuda:1')\nprompt_emb_sequence shape:\ntorch.Size([1, 1105, 3072])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"only_text_input = \"\"\"\nsummarize in 5 sentences\n\nThe shape memory effect (SME) occurs because a temperature-induced phase transformation reverses deformation, as shown in the previous hysteresis curve. Typically the martensitic phase is monoclinic or orthorhombic (B19' or B19). Since these crystal structures do not have enough slip systems for easy dislocation motion, they deform by twinning—or rather, detwinning.\n\nMartensite is thermodynamically favored at lower temperatures, while austenite (B2 cubic) is thermodynamically favored at higher temperatures. Since these structures have different lattice sizes and symmetry, cooling austenite into martensite introduces internal strain energy in the martensitic phase. To reduce this energy, the martensitic phase forms many twins—this is called \"self-accommodating twinning\" and is the twinning version of geometrically necessary dislocations. Since the shape memory alloy will be manufactured from a higher temperature and is usually engineered so that the martensitic phase is dominant at operating temperature to take advantage of the shape memory effect, SMAs \"start\" highly twinned.\n\nWhen the martensite is loaded, these self-accommodating twins provide an easy path for deformation. Applied stresses will detwin the martensite, but all of the atoms stay in the same position relative to the nearby atoms—no atomic bonds are broken or reformed (as they would be by dislocation motion). Thus, when the temperature is raised and austenite becomes thermodynamically favored, all of the atoms rearrange to the B2 structure which happens to be the same macroscopic shape as the B19' pre-deformation shape. This phase transformation happens extremely quickly and gives SMAs their distinctive \"snap.\"\n\nRepeated use of the shape-memory effect may lead to a shift of the characteristic transformation temperatures (this effect is known as functional fatigue, as it is closely related with a change of microstructural and functional properties of the material). The maximum temperature at which SMAs can no longer be stress induced is called Md, where the SMAs are permanently deformed.\n\"\"\"\nresponse = llm_model.generate_text_response(only_text_input)\nprint(response)\n# torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:33.741786Z","iopub.execute_input":"2025-04-24T17:39:33.742021Z","iopub.status.idle":"2025-04-24T17:39:39.294760Z","shell.execute_reply.started":"2025-04-24T17:39:33.742005Z","shell.execute_reply":"2025-04-24T17:39:39.293723Z"}},"outputs":[{"name":"stdout","text":"\nIn summary, the shape memory effect is a unique property of certain metals and alloys that allows them to return to their original shape after being deformed, and this property is exploited in various applications such as self-healing materials, actuators, and sensors. The shape memory effect is a result of the martensitic phase forming self-accommodating twins, which provide an easy path for deformation when the material is loaded. When the temperature is raised and austenite becomes thermodynamically favored, all of the atoms rearrange to the B2 structure, which happens to be the same macroscopic shape as the B19' pre-deformation shape. This phase transformation happens extremely quickly and gives SMAs their distinctive \"snap.\"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# ****Starting The Server Fast API****","metadata":{}},{"cell_type":"code","source":"!pip install fastapi uvicorn nest-asyncio pyngrok --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:39.295761Z","iopub.execute_input":"2025-04-24T17:39:39.296047Z","iopub.status.idle":"2025-04-24T17:39:43.831742Z","shell.execute_reply.started":"2025-04-24T17:39:39.296023Z","shell.execute_reply":"2025-04-24T17:39:43.830979Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install python-multipart\n!pip install fastapi uvicorn pyngrok python-multipart nest_asyncio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:43.832718Z","iopub.execute_input":"2025-04-24T17:39:43.832937Z","iopub.status.idle":"2025-04-24T17:39:50.240353Z","shell.execute_reply.started":"2025-04-24T17:39:43.832916Z","shell.execute_reply":"2025-04-24T17:39:50.239588Z"}},"outputs":[{"name":"stdout","text":"Collecting python-multipart\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nInstalling collected packages: python-multipart\nSuccessfully installed python-multipart-0.0.20\nRequirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\nRequirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\nRequirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.5)\nRequirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\nRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from fastapi import FastAPI, File, UploadFile, Query,  Request \nfrom pydantic import BaseModel\nimport base64\nfrom typing import Any\nfrom fastapi.middleware.cors import CORSMiddleware\nimport nest_asyncio\nfrom pyngrok import ngrok\nimport shutil\nimport os\nimport io\nimport uvicorn\nimport threading\nres = \"a\"\napp = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_methods=[\"OPTIONS\", \"POST\"],  # Explicitly list methods\n    allow_headers=[\"*\"],\n)\nclass AudioRequest(BaseModel):\n    filename: str\n    content_type: str\n    audio_data: str\n\nUPLOAD_DIR = \"uploads\"\nos.makedirs(UPLOAD_DIR, exist_ok=True)\n@app.post(\"/upload\")\nasync def upload_audio(audio_req: AudioRequest):\n    audio_bytes = base64.b64decode(audio_req.audio_data)\n    file_path = os.path.join(UPLOAD_DIR, \"newAudio.wav\")\n    with open(file_path, \"wb\") as buffer:\n        shutil.copyfileobj(io.BytesIO(audio_bytes), buffer)\n    result = user_inference(llm_model,file_path,user_prompt=\"text_prompt\")\n    print(result)\n    return {\"response\": result}\n@app.options(\"/model\")\nasync def options_model():\n    return {\"message\": \"OK\"}\n\n@app.post(\"/model\")\nasync def post_model(request: Request):\n    data = await request.json()\n    result = llm_model.generate_text_response(data.get('prompt'))\n    print(result)\n    return {\"response\": result}\n# @app.options(\"/model\")\n# async def options_model():\n#     return {\"message\": \"Audio uploaded successfully\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:50.241458Z","iopub.execute_input":"2025-04-24T17:39:50.241714Z","iopub.status.idle":"2025-04-24T17:39:50.906457Z","shell.execute_reply.started":"2025-04-24T17:39:50.241690Z","shell.execute_reply":"2025-04-24T17:39:50.905612Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!ngrok config add-authtoken 2uMIRA3ZadTWnAb0gDkOnhX4Soz_7PwZiNj6n5DwWMujFdLsm\n!pip install python-multipart\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:50.907429Z","iopub.execute_input":"2025-04-24T17:39:50.907730Z","iopub.status.idle":"2025-04-24T17:39:55.198857Z","shell.execute_reply.started":"2025-04-24T17:39:50.907700Z","shell.execute_reply":"2025-04-24T17:39:55.198105Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \nRequirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import nest_asyncio\nimport uvicorn\nfrom threading import Thread\nfrom fastapi import FastAPI\nfrom pyngrok import ngrok\n\n\n# Allow FastAPI to run inside Jupyter\nnest_asyncio.apply()\n\npublic_url = ngrok.connect(8081)\nprint(f\"Public URL: {public_url}\")\n\n# Run FastAPI app in a background thread\ndef run():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8081)\n\nthread = threading.Thread(target=run)\nthread.start()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:55.199836Z","iopub.execute_input":"2025-04-24T17:39:55.200049Z","iopub.status.idle":"2025-04-24T17:39:55.488223Z","shell.execute_reply.started":"2025-04-24T17:39:55.200029Z","shell.execute_reply":"2025-04-24T17:39:55.486814Z"}},"outputs":[{"name":"stdout","text":"Public URL: NgrokTunnel: \"https://58d8-34-55-218-130.ngrok-free.app\" -> \"http://localhost:8081\"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import subprocess\n\nsubprocess.run(\"pkill -f uvicorn\", shell=True)  # Linux/macOS\nprint(\" Killed all Uvicorn processes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:39:55.489138Z","iopub.execute_input":"2025-04-24T17:39:55.489474Z","iopub.status.idle":"2025-04-24T17:39:55.515139Z","shell.execute_reply.started":"2025-04-24T17:39:55.489452Z","shell.execute_reply":"2025-04-24T17:39:55.508502Z"}},"outputs":[{"name":"stdout","text":" Killed all Uvicorn processes\n","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [31]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8081 (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     156.192.134.135:0 - \"OPTIONS /upload HTTP/1.1\" 200 OK\ncombined_embeds:\ntensor([[[ 1.2634e-02,  2.6855e-02, -1.0559e-02,  ...,  4.5166e-03,\n           1.3245e-02, -2.0386e-02],\n         [ 1.0254e-02,  1.3477e-01, -2.0020e-02,  ...,  1.0559e-02,\n           3.4180e-02,  2.5024e-02],\n         [-8.6060e-03,  1.4587e-02, -9.8267e-03,  ..., -3.7354e-02,\n           1.2894e-03,  3.8086e-02],\n         ...,\n         [ 1.9016e+00, -1.0122e-01,  1.2884e+00,  ...,  1.5275e+00,\n          -1.2040e-01,  3.7825e-01],\n         [ 1.1603e+00,  1.5421e-01,  6.5329e-01,  ...,  1.0374e+00,\n          -1.2885e-01,  4.1804e-01],\n         [ 3.5571e-01,  1.2862e-01,  1.6443e-01,  ...,  2.2094e-01,\n          -9.3430e-02,  2.0325e-01]]], device='cuda:1')\ncombined_embeds shape:\ntorch.Size([1, 830, 3072])\nprompt_emb_sequence:\ntensor([[[ 0.0547, -0.0388, -0.0757,  ..., -0.0005,  0.0023,  0.0005],\n         [ 0.0219, -0.0352,  0.0055,  ..., -0.0233, -0.0206,  0.0064],\n         [-0.0078, -0.0425, -0.0043,  ...,  0.0247,  0.0167,  0.0415],\n         ...,\n         [-0.0205,  0.0031,  0.0062,  ...,  0.0101,  0.0057, -0.0048],\n         [-0.0078, -0.0425, -0.0043,  ...,  0.0247,  0.0167,  0.0415],\n         [ 0.0182, -0.0532, -0.0156,  ...,  0.0057,  0.0012, -0.0063]]],\n       device='cuda:1')\nprompt_emb_sequence shape:\ntorch.Size([1, 843, 3072])\nIn Boys, Idaho, a courageous group of firefighters responded to cries for help from two parrots. The crew scoured a burning home, searching for people in need of assistance. To their surprise, they found a pair of squawking birds, who had been left alone when the flames began to sweep the property.\n\nThe tropical creatures appeared to have known what to do, and both were pulled from the home and given oxygen. They are expected to survive the fire. The firefighters initially thought they were chasing human voices when they found the birds.\n\nThe officials treated the birds with oxygen masks, and both are expected to recover. The cause of the fire was contained to just one room, and it is currently being investigated. However, no people were found inside the home. Authorities have yet to track down the bird's owners.\n\nThis remarkable incident highlights the bravery and resourcefulness of the firefighters, as well as the unexpected role these parrots played in the rescue effort. It also raises questions about the safety of leaving exotic pets unattended during emergencies.\n\nAs the investigation continues, the community will likely learn more about the circumstances surrounding the fire and the birds' owners. In the meantime, the firefighters and the parrots have become local heroes, reminding us of the importance of compassion and adaptability in times of crisis.\n\nThe story of the firefighters and the parrots serves as a reminder that even in the most unexpected situations, there is always a chance for heroism and a chance for survival.\nINFO:     156.192.134.135:0 - \"POST /upload HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":16}]}